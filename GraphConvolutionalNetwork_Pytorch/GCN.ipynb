{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init and Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"./tmp_dataset\"\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"./tmp_saved_models/\"\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
    "# Files to download\n",
    "pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph representation\n",
    "\n",
    "Mathematically, a graph ($\\mathcal{G}$) is defined as a tuple of a set of nodes/vertices ($V$), and a set of edges/links ( $E$: $\\mathcal{G}=(V,E)$ ). For instance:\n",
    "\n",
    "<center width=\"100%\" style=\"padding:10px\"><img src=\"example_graph.svg\" width=\"250px\"></center>\n",
    "\n",
    "- Vertices $V=\\{1,2,3,4\\}$\n",
    "- Edges $E=\\{(1,2), (2,3), (2,4), (3,4)\\}$\n",
    "- We assume the graph to be undirected and hence don't add mirrored pairs like $(2,1)$\n",
    "\n",
    "For an undirected graph, $A$ is a symmetric matrix ($A_{ij}=A_{ji}$). We have the following adjacency matrix:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "    0 & 1 & 0 & 0\\\\\n",
    "    1 & 0 & 1 & 1\\\\\n",
    "    0 & 1 & 0 & 1\\\\\n",
    "    0 & 1 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Expressing a graph as a **list of edges** is **more efficient** in terms of memory and (possibly) computation, but using an adjacency matrix simpler to implement.\n",
    "- _We will implement the adjacency matrix_ to keep the code simple.\n",
    "- Alternatively, we could also use the list of edges to _define a sparse adjacency matrix_ with which we can work as if it was a dense matrix, but allows more memory-efficient operations.\n",
    "\n",
    "\n",
    "## Graph Convolutions\n",
    "\n",
    "- GCNs are similar to convolutions in images in the sense that the “filter” parameters are typically shared over all locations in the graph.\n",
    "- At the same time, GCNs rely on message passing methods, which means that vertices exchange information with the neighbors, and send “messages” to each other.\n",
    "\n",
    "1. The first step is that each node creates a feature vector that represents the message it wants to send to all its neighbors.\n",
    "2. In the second step, the messages are sent to the neighbors, so that a node receives one message per adjacent node. \n",
    "\n",
    "Below we have visualized the two steps for our example graph. \n",
    "\n",
    "<center width=\"100%\" style=\"padding:10px\"><img src=\"graph_message_passing.svg\" width=\"700px\"></center>\n",
    "\n",
    "**How to combine all the messages a node receives?**<br>\n",
    "As the number of messages vary across nodes, we need an operation that works for any number. Hence, **sum** or **take the mean.**.\n",
    "The GCN layer is defined as follows:\n",
    "\n",
    "$$H^{(l+1)} = \\sigma\\left(\\hat{D}^{-1/2}\\hat{A}\\hat{D}^{-1/2}H^{(l)}W^{(l)}\\right)$$\n",
    "\n",
    "Looking at the equation from **right to left:**\n",
    "\n",
    "$H^{(l)}$ : the previous features of **all** nodes. Each row represents the feature vector of a node.\n",
    "\n",
    "$W^{(l)}$ :  the weight matrix of learnable parameters at layer $l$.\n",
    "\n",
    "$H^{(l)}W^{(l)}$ : the weighted average of the previous features (new messages)\n",
    "\n",
    "$A$ : the adjacency matrix\n",
    "\n",
    "$\\hat{A}=A+I$ : we add the identity matrix to the adjacency matrix so that each node sends its own message to itself too\n",
    "\n",
    "$\\hat{D}$ : the diagonal degree matrix corresponding to $\\hat{A}$, where each diagonal entry $D_{ii}$ represents the number of neighbors (including itself, due to $I$) of node $i$. This matrix is used for normalization purposes.\n",
    "\n",
    "$\\hat{D}^{-1/2}$ : is the inverse square root of the degree matrix. For a diagonal matrix, this operation is performed element-wise on the diagonal.\n",
    "\n",
    "$\\hat{D}^{-1/2}\\hat{A}\\hat{D}^{-1/2}$ : this term serves as a normalization technique for the adjacency matrix, preventing the scale of node features from growing or shrinking drastically as they propagate through the network layers. In other words, this normalization ensures that nodes with many connections don't overwhelm the computation, and nodes with fewer connections aren't overlooked.\n",
    "\n",
    "$\\sigma$ : represents an arbitrary activation function, and not necessarily the sigmoid (usually a ReLU-based activation function is used in GNNs).\n",
    "\n",
    "$H^{(l+1)}$ : the new (current) features of **all** nodes\n",
    "\n",
    "> Note: the standard matrix multiplication is the dot product, for example in $H^{(l)}W^{(l)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            c_in (int): Number of input features per node.\n",
    "            c_out (int): Number of output features per node.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # the weight matrix W in the GCN equation\n",
    "        # a linear transformation layer to project input features to output features\n",
    "        self.projection = nn.Linear(c_in, c_out)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix):\n",
    "        \"\"\"\n",
    "        The forward pass.\n",
    "        Assumes identity connections (i.e., self-connections) are already added to the adjacency matrix.\n",
    "\n",
    "        Args:\n",
    "            node_feats: Node feature tensor of shape [batch_size, num_nodes, c_in]\n",
    "            adj_matrix: Adjacency matrix tensor of shape [batch_size, num_nodes, num_nodes]\n",
    "        Returns:\n",
    "            Updated node features of shape [batch_size, num_nodes, c_out]\n",
    "        \"\"\"\n",
    "        # Calculate the number of neighbors (incoming edges) for each node by summing over the last dimension of the adjacency matrix. The resulting tensor has shape [batch_size, num_nodes, 1], where each value represents the number of neighbors\n",
    "        num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
    "\n",
    "        # Project node features using the weight matrix W\n",
    "        new_node_feats = self.projection(node_feats)\n",
    "\n",
    "        # matrix multiplication of adjacency matrix and each node features\n",
    "        # aggregating features from neighboring nodes for each node\n",
    "        # from: https://pytorch.org/docs/stable/generated/torch.bmm.html\n",
    "        # if mat1 is (b×n×m) and mat2 is (b×m×p), the result will be a (b×n×p) tensor\n",
    "        av_node_feats = torch.bmm(adj_matrix, new_node_feats)\n",
    "\n",
    "        # Normalize the aggregated features by dividing by the number of neighbors.\n",
    "        # This takes the mean of the neighbors' features instead of summing.\n",
    "        # Shape remains [batch_size, num_nodes, c_out]\n",
    "        norm_node_feats = av_node_feats / num_neighbours\n",
    "\n",
    "        return norm_node_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to draw the graph from the adjacency matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch\n",
    "\n",
    "def visualize_graph(adj_matrix, remove_self_loops=True, title=\"Graph Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualize a graph from an adjacency matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    adj_matrix (torch.Tensor): Adjacency matrix of shape [batch_size, num_nodes, num_nodes]\n",
    "    remove_self_loops (bool): If True, removes the identity matrix from adj_matrix\n",
    "    title (str): Title for the plot\n",
    "    \n",
    "    Returns:\n",
    "    matplotlib.figure.Figure: The figure containing the graph visualization\n",
    "    \"\"\"\n",
    "    # Ensure the input is a 3D tensor\n",
    "    if adj_matrix.dim() == 2:\n",
    "        adj_matrix = adj_matrix.unsqueeze(0)\n",
    "    \n",
    "    # Remove self-loops if specified\n",
    "    if remove_self_loops:\n",
    "        identity = torch.eye(adj_matrix.size(1)).unsqueeze(0).to(adj_matrix.device)\n",
    "        adj_matrix = adj_matrix - identity\n",
    "    \n",
    "    # Convert to numpy for NetworkX\n",
    "    adj_np = adj_matrix.squeeze().cpu().numpy()\n",
    "\n",
    "    # Create a graph\n",
    "    G = nx.Graph(adj_np)\n",
    "\n",
    "    # Set up the plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Draw the graph\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, ax=ax, with_labels=True, node_color='lightblue', \n",
    "            node_size=500, font_size=16, font_weight='bold')\n",
    "\n",
    "    # Add edge labels\n",
    "    edge_labels = {(u, v): '' for u, v in G.edges()}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, ax=ax)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(title, fontsize=16)\n",
    "\n",
    "    # Remove axis\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "\n",
      "Adjacency matrix:\n",
      " tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "# 1 batch, 4 nodes per batch, 2 features per node\n",
    "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
    "\n",
    "# note that the identity connections are already included in the adjacency matrix\n",
    "adj_matrix = torch.Tensor([[[1, 1, 0, 0],\n",
    "                            [1, 1, 1, 1],\n",
    "                            [0, 1, 1, 1],\n",
    "                            [0, 1, 1, 1]]])\n",
    "\n",
    "print(\"Node features:\\n\", node_feats)\n",
    "print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
